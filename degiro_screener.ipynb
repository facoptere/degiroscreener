{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4347c53-7302-42f7-903d-68b80a568255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPORTATIONS\n",
    "import logging\n",
    "import os\n",
    "from degiro_connector.trading.models.trading_pb2 import Credentials, ProductSearch\n",
    "import degiro_connector.core.helpers.pb_handler as pb_handler\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from multiprocessing import  Pool\n",
    "from functools import partial\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import math\n",
    "import itertools\n",
    "from cachedApi import cachedApi\n",
    "from DictObj import DictObj\n",
    "\n",
    "def isna(num):\n",
    "    return num!= num    \n",
    "\n",
    "def get(d,k):\n",
    "    r = np.NaN # sys.float_info.epsilon #float(\"nan\")np.NaN\n",
    "    if d is not None and (type(d) is dict) and k in d:\n",
    "        r = d[k]\n",
    "        if (type(r) is dict) and ('value' in r):\n",
    "            r = r['value']\n",
    "    else:\n",
    "        r = np.NaN\n",
    "    return r\n",
    "\n",
    "def getmin(d,a): # get min of defined parameter in array a\n",
    "    r = 10**6\n",
    "    isset = False\n",
    "    for p in a:\n",
    "        v = get(d, p)\n",
    "        if v == v:\n",
    "            r = min(r, v)\n",
    "            isset = True\n",
    "    if isset:\n",
    "        return r\n",
    "    else:\n",
    "        return np.NaN\n",
    "            \n",
    "    \n",
    "def yget(d,k):\n",
    "    r = np.NaN # sys.float_info.epsilon #float(\"nan\")np.NaN\n",
    "    if d is not None and k in d:\n",
    "        r=d[k]\n",
    "        if (type(r) is dict) and ('value' in r):\n",
    "            r = r['value']\n",
    "    else:\n",
    "        r = np.NaN\n",
    "    try:\n",
    "        r = float(r)\n",
    "    except:\n",
    "        r = str(r)\n",
    "        if r == 'None' or r == '':\n",
    "            r = np.NaN\n",
    "    return r\n",
    "\n",
    "def write2fav(df):\n",
    "    if (df.shape[0] > 0):\n",
    "        username = os.getenv(\"GT_DG_USERNAME\") or \"\"\n",
    "        password = os.getenv(\"GT_DG_PASSWORD\") or \"\"\n",
    "\n",
    "        if username == \"\" or password == \"\":\n",
    "            exit(0)\n",
    "\n",
    "        credentials = Credentials(\n",
    "            int_account=None, # updated by get_client_details()\n",
    "            username=username,\n",
    "            password=password,\n",
    "        )\n",
    "\n",
    "\n",
    "        trading_api = cachedApi('/home/fab/GamestonkTerminal/.cachedb',credentials)\n",
    "        trading_api.connect()\n",
    "        trading_api.get_products_config(raw=True)\n",
    "        trading_api.get_client_details()\n",
    "        \n",
    "        now = datetime.now()\n",
    "        prefix='Screener-'\n",
    "        fl = trading_api.get_list_list()\n",
    "        #print(fl)\n",
    "        for l in fl['data']:\n",
    "            if 'name' in l and l['name'].startswith(prefix):\n",
    "                trading_api.delete_favourite_list(id=l['id'])\n",
    "                print(f'Deleting DEGIRO favourite list \\\"{l[\"name\"]}\\\"')\n",
    "        name=prefix+now.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "        print(f'Creating DEGIRO favourite list \\\"{name}\\\"')\n",
    "        favorite_list_id = trading_api.create_favourite_list(name=name)\n",
    "        for p in df.index[:50].tolist():  \n",
    "            # list is limited to 50 entries\n",
    "            trading_api.put_favourite_list_product(id=favorite_list_id,product_id=p)\n",
    "            #print(f'Adding product id {p}')\n",
    "        trading_api.logout() \n",
    "\n",
    "def write2csv(df):\n",
    "    now = datetime.now() # current date and time\n",
    "    filename=\"degiro-export-\"+now.strftime(\"%Y-%m-%d-%H-%M\")+\".csv\"\n",
    "    filepath='.'\n",
    "    fullpath=os.path.join(filepath,filename)\n",
    "    print(f\"Writing csv file '{fullpath}' (encoding utf-8)\")\n",
    "    df.to_csv(fullpath, index=True, sep=str(';'), decimal=str(','),encoding='utf-8', )\n",
    "\n",
    "        \n",
    "def parallelize_dataframe(df, func, n_cores=os.cpu_count()):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "def assess_map(product, eee):\n",
    "    p = DictObj(dict(product))\n",
    "    row = {}\n",
    "    #if p.isin != 'PTGNV0AM0001': return row\n",
    "    #print(p)\n",
    "    try:\n",
    "        company_profile = trading_api.get_company_profile(product_isin=p.isin, raw=True)\n",
    "        row['symbol'] = p.symbol\n",
    "        row['isin'] = p.isin\n",
    "        row['id'] = p.id\n",
    "        row['vwdId'] = f'{p.vwdIdentifierType}:{p.vwdId}' if hasattr(p, 'vwdId') and hasattr(p, 'vwdIdentifierType') else ''\n",
    "        row['vwdIdSecondary'] = f'{p.vwdIdentifierTypeSecondary}:{p.vwdIdSecondary}' if hasattr(p, 'vwdIdSecondary') and hasattr(p, 'vwdIdentifierTypeSecondary') else ''\n",
    "        \n",
    "        row['name'] = p.name.upper()\n",
    "        row['sector'] =   yget(company_profile, 'sector')  \n",
    "        row['industry'] = yget(company_profile, 'industry')\n",
    "        '''\n",
    "        desc = yget(company_profile, 'businessSummary')\n",
    "        if desc is not None and type(desc) == str:\n",
    "            desc = desc.upper()\n",
    "            if re.match(r'.*((POTASH|NITROGEN|PHOSPHATE|CROP NUTRIENT|CROP INPUT|FERTILIZER|FEEDING).*?){3}', desc):\n",
    "                row['industry'] = '!!' + row['industry']\n",
    "        '''\n",
    "        if isinstance(row['industry'], str): row['industry'] = row['industry'].replace(' (NEC)', '')\n",
    "        row['country'] = yget(company_profile, 'country') \n",
    "        row['eee'] = 1 if row['country'] in eee else 0\n",
    "        \n",
    "        row['volume'] = get(company_profile,\"VOL10DAVG\") or yget(company_profile, 'volume')\n",
    "        #row['volume'] = row['volume'] / 1000 if not pd.isna(row['volume'])\n",
    "        row['marketCap'] = get(company_profile,\"MKTCAP\") or yget(company_profile, 'marketCap')  \n",
    "        if not pd.isna(row['marketCap']):\n",
    "            row['marketCap'] /= 1000\n",
    "        row['closePrice'] = p.closePrice if hasattr(p, 'closePrice') else 0 # price shown on screen, depends on the stock exchange\n",
    "        row['Cur'] = p.currency if hasattr(p, 'currency') else '' # currency shown on screen\n",
    "        if row['Cur'] == 'EUR':\n",
    "            row['sortCur'] = 3 # sortCur is a temp column used to determine which exchange to keep when a stock is listed on different place. Higher value means more change to be selected\n",
    "        elif row['Cur'] == 'USD':\n",
    "            row['sortCur'] = 1\n",
    "        else:\n",
    "            row['sortCur'] = 0\n",
    "\n",
    "        codes = trading_api.get_company_ratios(product_isin=p.isin, raw=True)\n",
    "        #display(codes)\n",
    "        row['StmPrice'] = get(codes,\"NPRICE\") # price used to compute statements, ratio, etc\n",
    "        row['StmCur'] = get(codes,\"priceCurrency\") # currency used to compute market capitalization, statements, ratio, etc\n",
    "        row['Δ1Y%'] = get(codes,\"PR52WKPCT\") # price diff 1 year\n",
    "        row['Δ13W%'] = get(codes,\"PR13WKPCT\") # price diff 3 months\n",
    "        row['Δ1W%'] = get(codes,\"PR5DAYPRC\") # price diff 1 week\n",
    "        row['Δ1D%'] =get(codes,\"PR1DAYPRC\")\n",
    "\n",
    "        if row['vwdId']:\n",
    "            df = trading_api.get_longtermprice(row['vwdId'])\n",
    "            df = df[-200:]\n",
    "            mean200D = np.NaN\n",
    "            if df.shape[0] == 200:\n",
    "                mean200D = df['close'].mean()\n",
    "                row['%M200D'] = (row['closePrice'] - mean200D) / mean200D\n",
    "            elif df.shape[0] == 0 and row['vwdIdSecondary']:\n",
    "                df = trading_api.get_longtermprice(row['vwdIdSecondary'])\n",
    "                df = df[-200:]\n",
    "                mean200D = np.NaN\n",
    "                if df.shape[0] == 200:\n",
    "                    mean200D = df['close'].mean()\n",
    "                    row['%M200D'] = (row['closePrice'] - mean200D) / mean200D\n",
    "        if not '%M200D'in row:\n",
    "            row['%M200D'] = np.NaN\n",
    "            #print(f\"Cannot get 200-day chart data for {p.name}\")\n",
    "        \n",
    "        h = get(codes,\"NHIG\")\n",
    "        l = get(codes,\"NLOW\")\n",
    "        row['L%H'] = int(100*(row['StmPrice'] - l)/(h-l)) if not pd.isna(h) and not pd.isna(l) and not pd.isna(row['StmPrice']) and h>l else np.NaN\n",
    "\n",
    "        row['Yield'] =  get(codes,'YLD5YAVG') # dividend yield\n",
    "        row['Payout'] =  get(codes,'TTMPAYRAT') # dividend yield\n",
    "        row['β'] = get(codes,\"BETA\") # correlation \n",
    "        row['Reco'] = get(codes,'ratings_CURR') # current recommendation\n",
    "        row['ΔFOCF5'] = get(codes,'FOCF_AYr5CAGR') # increase of free operational cash flow, 5Y CAGR\n",
    "        row['P/FCF'] = get(codes,'TTMPRFCFPS') # Price to Free Cash Flow per Share - trailing 12 months\n",
    "\n",
    "        a = get(codes,'TTMFCF') # Free Cash Flow - trailing 12 month\n",
    "        b = get(codes,'TTMNIAC') # Net Income available to common - trailing 12 months\n",
    "        row['FCF/NI'] = a/b if not pd.isna(a) and not pd.isna(b) and b > 0 else np.NaN\n",
    "\n",
    "        \n",
    "        row['ΔREV'] = get(codes,\"REVCHNGYR\")  # Revenue Change % - most recent quarter 1 year ago\n",
    "        row['ΔREV3'] = get(codes,\"REVGRPCT\")  # \"Growth rate% -  Revenue, 3 year\";\n",
    "        row['ΔREV5'] = get(codes,\"REVTRENDGR\")  # \"Revenue growth rate, 5 year\"; REVPS5YGR \"Revenue/share (5 yr growth)\"; -- should be > 0\n",
    "        if pd.isna(row['ΔREV5']):\n",
    "            row['ΔREV5'] = yget(company_profile, 'revenueGrowth')\n",
    "        row['ΔΔREV1-3'] = row['ΔREV'] - row['ΔREV3']\n",
    "        row['ΔΔREV3-5'] = row['ΔREV3'] - row['ΔREV5'] \n",
    "        \n",
    "        row['ΔNPM'] = get(codes,\"TTMNPMGN\") # Net Profit Margin % - trailing 12 month\"\n",
    "        row['ΔNPM5'] = get(codes,\"NPMTRENDGR\") # \"Net Profit Margin growth rate, 5 year\"; -- should be > 0\n",
    "        row['ΔΔNPM1-5'] = row['ΔNPM'] - row['ΔNPM5'] \n",
    "        \n",
    "        row['ΔEPS'] = get(codes,'TTMEPSCHG')   # latest \"Growth rate% - EPS, TTM\";\n",
    "        if pd.isna(row['ΔEPS']):\n",
    "            row['ΔEPS'] = yget(company_profile, 'earningsGrowth')\n",
    "        row['ΔEPS3'] = get(codes,\"EPSGRPCT\")   # \"EPS Growth rate % - , 3 year CAGR\";\n",
    "        row['ΔEPS5'] = get(codes,\"EPSTRENDGR\") # \"EPS growth rate %, 5 year CAGR\";\n",
    "\n",
    "        row['ΔΔEPS1-3'] = row['ΔEPS'] - row['ΔEPS3']\n",
    "        row['ΔΔEPS3-5'] = row['ΔEPS3'] - row['ΔEPS5'] \n",
    "        row['ROEpct'] = get(codes,'TTMROEPCT')           # Return on average equity - trailing 12 month -- should be >20%\n",
    "        if pd.isna(row['ROEpct']):\n",
    "            row['ROEpct'] = yget(company_profile, 'returnOnEquity')\n",
    "        row['ROE5Ypct'] = get(codes,'AROE5YAVG')         # Return on average equity avg 5Y -- should be >20%\n",
    "        \n",
    "        row['ΔROE'] = row['ROEpct'] - row['ROE5Ypct'] \n",
    "        \n",
    "        row['P2TB'] = get(codes,'APR2TANBK')             # price to tangible book\n",
    "        #row['dP2TB'] = get(codes,'BVTRENDGR')           # growth of price to tangible book, 5Y CAGR\n",
    "        row['P2B'] = get(codes,'APRICE2BK')              # price to  book\n",
    "        if pd.isna(row['P2B']):\n",
    "            row['P2B'] = yget(company_profile, 'priceToBook')\n",
    "        #row['dP2B'] = get(codes,'TanBV_AYr5CAGR')       # growth of P25B, 5Y\n",
    "        row['PCF'] =  get(codes,'TTMPRCFPS')             # \"Price to Cash Flow per share, near 1 idealy\n",
    "\n",
    "        row['PE'] = get(codes,'PEINCLXOR')               #  P/E including extraordinary items - TTM - should be <50%\n",
    "        if pd.isna(row['PE']):\n",
    "            row['PE'] = yget(company_profile, 'trailingPE')\n",
    "        row['fPE'] = get(codes,'ProjPE')          # forward PE\n",
    "        if pd.isna(row['fPE']):\n",
    "            row['fPE'] = yget(company_profile, 'forwardPE')\n",
    "\n",
    "        row['PEG'] = row['PE'] / row['ΔEPS3'] if row['ΔEPS3'] and row['ΔEPS3']>0 else np.NaN # PEG ratio, should be <1\n",
    "        if pd.isna(row['PEG']):\n",
    "            row['PEG'] = yget(company_profile, 'pegRatio')\n",
    "        row['fPEG'] = row['fPE'] / row['ΔEPS3']  if row['ΔEPS3'] and row['ΔEPS3']>0 else np.NaN    # forward PEG ratio, should be <1\n",
    "\n",
    "        row['PS'] = get(codes,'TTMPR2REV')               #  Price to sales - trailing 12 month  -- should be between 2 to 4\n",
    "        if pd.isna(row['PS']):\n",
    "            row['PS'] = yget(company_profile, 'priceToSalesTrailing12Months')\n",
    "        row['fPS'] = get(codes,'Price2ProjSales') # forward PS -- should be 2 to 4/\n",
    "            \n",
    "        row['%DEBT'] =  get(codes,'QTOTD2EQ') #\"Total debt/total equity, percent, should be <100%\n",
    "        row['QLTD2EQ'] =  get(codes,'QLTD2EQ') #\"Total debt/total equity, percent, should be <100%\n",
    "        row['QCURRATIO'] =  get(codes,'QCURRATIO') #\"Total debt/total equity, percent, should be <100%\n",
    "        if pd.isna(row['%DEBT']):\n",
    "            row['%DEBT'] = yget(company_profile, 'debtToEquity')\n",
    "        row['%DEBT'] = round(row['%DEBT']) if not pd.isna(row['%DEBT']) else np.NaN\n",
    "        row['BV'] =  get(codes,'QBVPS') # QTANBVPS\n",
    "        if pd.isna(row['BV']):\n",
    "            row['BV'] =  get(codes,'ABVPS') # ATANBVPS\n",
    "        if pd.isna(row['BV']):\n",
    "            row['BV'] =  get(codes,'QTANBVPS')  \n",
    "        if pd.isna(row['BV']):\n",
    "            row['BV'] =  get(codes,'ATANBVPS')  \n",
    "        if pd.isna(row['BV']):\n",
    "            row['BV'] =  yget(company_profile, 'bookValue')\n",
    "        row['BV'] =  (1 * (row['BV'] - row['StmPrice']) / row['StmPrice']) if not pd.isna(row['BV']) and not pd.isna(row['StmPrice']) and row['BV'] > 0 and row['StmPrice'] > 0 else np.NaN \n",
    "        \n",
    "        # book value tangible / share price, last quarter >100% is fair\n",
    "\n",
    "        # ratio : intrinsic value from free cash flow per share / price per share - should be > 100%\n",
    "        # gain of free cash flow CAGR5Y is not available on DEGIRO, so I consider \"free operational\" cash flow\n",
    "        dFOCF =  get(codes,'FOCF_AYr5CAGR') # gain of  free operational cash flow, CAGR 5 year.\n",
    "        FCFS = get(codes,'TTMFCFSHR')   # free Cash Flow per share  - trailing 12 month\n",
    "        row['IV'] = FCFS*((1-((1+dFOCF/100)*0.85)**10)/(1-((1+dFOCF/100)*0.85))+10*(((1+dFOCF/100)*0.85)**10)) if not pd.isna(dFOCF) and not pd.isna(FCFS) else np.NaN\n",
    "        row['IV'] = (1*(FCFS-row['StmPrice'])/row['StmPrice']) if not pd.isna(row['StmPrice']) and row['StmPrice']>0 and not pd.isna(row['IV']) else np.NaN\n",
    "        \n",
    "        try:\n",
    "            # 1/ EPS\n",
    "            eps = get(codes,\"TTMEPSINCX\")   # \"EPS including extraordinary items - trailing 12 month\";\n",
    "            if not pd.isna(eps):\n",
    "                # 2/ growth rate min des 2 là, ou ΔEPS5?\n",
    "                gr = getmin(codes,[\"REVTRENDGR\", \"TanBV_AYr5CAGR\"]) #, \"EPSTRENDGR\", \"EPSGRPCT\"\n",
    "                # 3/ projPE ou le double du précédent, min\n",
    "                if not pd.isna(row['fPE']):\n",
    "                    ppe = min (row['fPE'], 2* gr)\n",
    "                else:\n",
    "                    ppe = 2* gr\n",
    "                fsv = eps*((1+gr/100)**5)*ppe/2                        \n",
    "                row['FV'] = (fsv-row['StmPrice'])/row['StmPrice'] # 0=> stock price will double in 5 years          \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #dFOCF \tFCFS\n",
    "        #BVS = get(codes,'ABVPS') #Book value (Total Equity) per share - most recent fiscal year\n",
    "        #FCF = p.StmPrice / get(codes,'TTMPRFCFPS') # Price to Free Cash Flow per Share - trailing 12 months\" \n",
    "        #dREV3 = get(codes,\"REVGRPCT\") #\"Growth rate% -  Revenue, 3 year\";\n",
    "        #dBVS5 = get(codes,\"BVTRENDGR\") #\"Book value per share growth rate, 5 year\";\n",
    "        #dTBE5 = get(codes,\"TanBV_AYr5CAGR\") #\"Tangible Book Value, Total Equity, 5 Year CAGR\";\n",
    "        #dCSP5 = get(codes,\"CSPTRENDGR\") # \"Capital Spending growth rate, 5 year\";      \n",
    "        #row['EV/EBITD'] = EV/EBITD if EV and EBITD and EBITD>0 else 0\n",
    "\n",
    "    except:\n",
    "        print(f\"Error profile {p.symbol}\")\n",
    "        traceback.print_exc()\n",
    "    return row    \n",
    "\n",
    "def myassess(country, stock_list, info_df):\n",
    "    eee = {}\n",
    "    try:\n",
    "        eee = {k:1 for k in pd.read_csv(\"eee.csv\", header=None).T.values[0]}\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if hasattr(stock_list, 'products'):\n",
    "            with ThreadPoolExecutor(max_workers = os.cpu_count()) as executor:\n",
    "                results = executor.map(assess_map, stock_list.products, itertools.repeat(eee))\n",
    "            #print(results)\n",
    "            row_df = pd.DataFrame(results)\n",
    "            if info_df.shape[0] == 0:\n",
    "                info_df = row_df\n",
    "            else:\n",
    "                info_df = pd.concat([info_df,row_df], ignore_index=True)\n",
    "            #display(info_df)\n",
    "        else:\n",
    "            print(\"Stock market as no product\", country)\n",
    "        #info_df = info_df.astype({'FV':'Int64', 'IV':'Int64', 'BV' :'Int64','%DEBT' :'Int64','L%H':'Int64','eee':'Int64'})\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        pass\n",
    "    return info_df\n",
    "\n",
    "\n",
    "#############            \n",
    "            \n",
    "logging.basicConfig(level=logging.FATAL) #\n",
    "\n",
    "username = os.getenv(\"GT_DG_USERNAME\") or \"\"\n",
    "password = os.getenv(\"GT_DG_PASSWORD\") or \"\"\n",
    "\n",
    "if username == \"\" or password == \"\":\n",
    "    exit(0)\n",
    "    \n",
    "credentials = Credentials(\n",
    "    int_account=None, # updated by get_client_details()\n",
    "    username=username,\n",
    "    password=password,\n",
    ")\n",
    "\n",
    "\n",
    "trading_api = cachedApi('/home/fab/GamestonkTerminal/.cachedb',credentials)\n",
    "trading_api.connect()\n",
    "\n",
    "try:\n",
    "    # get all product list, countries, marketplaces\n",
    "    products_config_dict = trading_api.get_products_config(raw=True)\n",
    "    # get IntAccount\n",
    "    trading_api.get_client_details()\n",
    "\n",
    "    # this is the main dataframe that will be filled up\n",
    "    info_df = pd.DataFrame()\n",
    "    \n",
    "    # stocked are browsed from counties(, and not marketplaces). This is the most reliable to get all stocks\n",
    "    for li_dict in trading_api.stockCountries:\n",
    "        li = DictObj(li_dict)\n",
    "        stock_country_id = li.id\n",
    "        country = trading_api.countries[li.country].name\n",
    "        #if country != 'HU': continue\n",
    "        # it's assumed that a country has less than 10x1000 stocks, so we browse up to 10 pages and stop once we got a partial page\n",
    "        for page in range(0,10):\n",
    "            request_stock = ProductSearch.RequestStocks(stock_country_id=stock_country_id,limit=1000,offset=page*1000,require_total=True)\n",
    "            stock_list = trading_api.product_search(request=request_stock, raw=False)\n",
    "            if hasattr(stock_list, 'products'):\n",
    "                size = len(stock_list.products)\n",
    "                print(f\"country:{country} list:All ({size} stocks for page {page+1})\")\n",
    "                # dowload data for all stocks in the list. It's multi-thread even though the cache system is mono-thread...\n",
    "                if stock_list: info_df = myassess(country, stock_list, info_df) \n",
    "                #for p in stock_list.products:\n",
    "                #    assess_map(p, {})\n",
    "                if size != 1000: break\n",
    "            else:\n",
    "                break\n",
    "    print(f\"Number of stock entries in all exchanges: {info_df.shape[0]}\")\n",
    "    info_df.set_index('id', inplace = True)\n",
    "    info_df.industry.fillna(\"—\", inplace=True)\n",
    "    info_df.loc[info_df.industry.str.match('.*(AGRICULTURAL|AGRICULTURE|AQUACULTURE|BAKERY|BEER|BEVERAGES|BOTTLED|BREAD|BREWERS|CANNABIS|'\\\n",
    "                               'CATTLE|CEREAL|CHEWING|CHOCOLATE|CIGARETTE|CIGARS|COCOA|COFFEE|DAIRY|DISCOUNT|DISTILLERIES|'\\\n",
    "                               'DISTILLERS|DRINKS|FARMING|FAT|FEED|FERTILIZERS|FISHING|FOOD|FOODS|FRUIT|GROCERY|LIQUOR|MALT|MEALS|MEAT|'\\\n",
    "                               'NON-ALCOHOLIC|NON-CHOCOLATE|NON-CYCLICAL|NUT|ORGANIC|PASTA|PEST|PESTICIDES|POULTRY|PULP|SEAFOOD|SNACK|'\\\n",
    "                               'STARCH|SUGAR|SUPERMARKETS|SWEETENERS|TEA|TOBACCO|VEGAN|VEGETABLE|VEGETARIAN|WINE|WINERIES|Household Products|Well?being|care products|personal products|restaurant).*', case=False),['sector']] = 'Staples/Food related'\n",
    "       \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(repr(e))\n",
    "    traceback.print_exc()\n",
    "\n",
    "try:\n",
    "    trading_api.logout()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(repr(e))\n",
    "    traceback.print_exc()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a1b97-b444-4c2e-a7cb-3432ae80bd09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def var2rank(X,Y,x):\n",
    "    r = 1 # default return if x is nan\n",
    "    try:\n",
    "        if x == x:\n",
    "            y_interp = interp1d(x=X, y=Y,fill_value=(Y[0], Y[-1]), bounds_error=False)\n",
    "            r = float(y_interp(x))\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        None\n",
    "    return r\n",
    "\n",
    "def var2quant(x,Q,name): \n",
    "    Y = Q.index.to_numpy()\n",
    "    Y = (Y-Y[0])/(Y[-1]-Y[0])+1\n",
    "    Y = np.asarray(Y)\n",
    "    X=list(Q[name].to_dict().values())\n",
    "    r = var2rank(X,Y,x[name])\n",
    "    return r\n",
    "\n",
    "def compute_rank(info_df, Q, k):\n",
    "    info_df['score'] = 1\n",
    "    for key, value in k.items():\n",
    "        info_df['score'] *= info_df.apply(lambda x: var2quant(x,Q,key), axis = 1) ** value\n",
    "    return info_df\n",
    "\n",
    "\n",
    "######         \n",
    "\n",
    "# compute quantile of all numeric parameters\n",
    "Q = info_df.quantile(q=[0.1,0.25,0.5,0.75,0.9])\n",
    "\n",
    "# per sector, correlation between 1YTTM gain and all other parameters. \n",
    "# Conglomerates are removed since result is the opposite from all other sector\n",
    "# then we merge all sector by computing the mean of correlation factor for each parameter\n",
    "#gainCorrelation=info_df.drop(info_df.index[ (info_df['Δ1Y%'] < Q['Δ1Y%'][0.75]) ])\n",
    "gainCorrelation=info_df.groupby('sector').corrwith(info_df['Δ1Y%'],method ='spearman').mean(axis=0)\n",
    "# Only some parameters are considered to compute the score\n",
    "gainCorrelation = gainCorrelation[ [\\\n",
    "                                    \"QLTD2EQ\", \"QCURRATIO\", \"Payout\", \"Yield\", \"β\", \\\n",
    "                                    \"Reco\", \"ΔFOCF5\", \"P/FCF\", \"FCF/NI\", \"ΔREV5\", \\\n",
    "                                    'ΔREV', 'ΔREV3', 'ΔΔREV1-3', 'ΔΔREV3-5', 'ΔΔNPM1-5', \\\n",
    "                                    \"ΔNPM5\", \"ΔNPM\", \"ΔEPS\", \"ΔEPS3\", \"ΔEPS5\", \\\n",
    "                                    'ΔΔEPS1-3', 'ΔΔEPS3-5', \"ROEpct\", \"ROE5Ypct\", 'ΔROE', \\\n",
    "                                    \"P2TB\", \"P2B\", \"PCF\", \"PE\", \"fPE\", \\\n",
    "                                    \"PEG\", \"fPEG\", \"PS\", \"fPS\", \"%DEBT\" ] ]\n",
    "# we normalize the power factors, we add the 1YTTM back in the table\n",
    "gainMax=gainCorrelation.abs().mean()\n",
    "gainCorrelation=gainCorrelation/gainMax\n",
    "gainCorrelation=dict(gainCorrelation.sort_values(ascending = False))\n",
    "gainCorrelation['Δ1Y%']=1\n",
    "\n",
    "#display(gainCorrelation)\n",
    "\n",
    "# compute the score for all stocks, using all CPU cores\n",
    "if info_df.shape[0] > os.cpu_count():\n",
    "    info_df = parallelize_dataframe(info_df,partial(compute_rank, Q=Q, k=gainCorrelation))\n",
    "else:\n",
    "    compute_rank(info_df, Q, gainCorrelation)\n",
    "\n",
    "info_df=info_df.sort_values(by='score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425b8b0-eb9a-44dc-9bd3-acdce4c2cffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 40)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "#display(info_df[:1])\n",
    "split=10**(max(1,math.floor(math.log(info_df.shape[0],10))-1))\n",
    "keeptop=math.floor(split*0.9)\n",
    "cropsector=10#max(5,math.floor(split/50))\n",
    "cropindustry=2#max(1,math.floor(cropsector/5))\n",
    "df = info_df.copy()\n",
    "\n",
    "# we remove duplicates when a stock is listed on several exchanges.\n",
    "df = df.sort_values(by=['name', 'sortCur', 'vwdId'], ascending = False).drop_duplicates(keep = 'first', subset = 'name')\n",
    "df = df.sort_values(by=['isin', 'sortCur', 'vwdId'], ascending = False).drop_duplicates(keep = 'first', subset = 'isin')\n",
    "print(f\"Number of stock entries after removing duplicates: {info_df.shape[0]}\")\n",
    "\n",
    "df['score'] = pd.qcut(df['score'].rank(method='first'),q=split, retbins=False, labels=False)\n",
    "df=df.drop(df.index[ (  (df['%M200D'] <0) | ((df['%M200D'].isna()) & (df['L%H'] < 45)) | (df['Δ1Y%'] < Q['Δ1Y%'][0.75])  | (df['score'] < keeptop) )])\n",
    "df=df.drop(df.index[ (  (df['IV'] < Q['IV'][0.5])   )])\n",
    "df=df.drop(df.index[ (  (df['ROE5Ypct'] < Q['ROE5Ypct'][0.5])   )])\n",
    "df=df.drop(df.index[ (  (df['Reco'] > Q['Reco'][0.75])   )])\n",
    "df=df.drop(df.index[ (  (df['%DEBT'] > Q['%DEBT'][0.9])   )])\n",
    "df=df.drop(df.index[ (  (df['ROEpct'] < Q['ROEpct'][0.9])   )])\n",
    "#df=df.drop(df.index[ ( (df['PE'] >Q['PE'][0.9]) | (df['%DEBT'] >Q['%DEBT'][0.9]) | (df['P2B'] >Q['P2B'][0.9]) | (df['Reco'] > Q['Reco'][0.5])  | (df['PEG'] > Q['PEG'][0.9])  | (df['IV'] < Q['IV'][0.5]) | (df['%M200D'] <0) | ((df['%M200D'].isna()) & (df['L%H'] < 45)) | (df['Δ1Y%'] < Q['Δ1Y%'][0.75])  )]) # | (df['PE'] >15) | (df['%DEBT'] >100) | (df['Δ1Y%'] < 8) |(df['P2TB'] >3) |(df['ΔREV5'] <5) |(df['ΔFOCF5'] <0) |(df['FV'] <-.50)  |(df['FCF/NI'] <0)\n",
    " # | (df['PE'] >15) | (df['%DEBT'] >100) | (df['Δ1Y%'] < 8) |(df['P2TB'] >3) |(df['ΔREV5'] <5) |(df['ΔFOCF5'] <0) |(df['FV'] <-.50)  |(df['FCF/NI'] <0)\n",
    "#df=df.drop(df.index[ (  | (df['sector'] == \"Financial\") | (df['sector'] == \"Transportation\") )]) #| (df['Reco'] > 2.4) | (df['Δ1Y%'] < 20) | (df['FCF/NI'] <0) |(df['P2B'] >15) |(df['ΔREV'] <0) | (df['%DEBT'] >120)  | (df['industry'].str.contains(\"harma\")) | (df['sector'].str.contains(\"inanc\")) |(df['FV'] <-.35)      | (df['PE'] >15) | (df['%DEBT'] >100) | (df['Δ1Y%'] < 8) |(df['P2TB'] >3) |(df['ΔREV5'] <5) |(df['ΔFOCF5'] <0) |(df['FV'] <-.50)  |(df['FCF/NI'] <0)\n",
    "\n",
    "#print(f\"Quantiles:{split}, keeping top {keeptop}th and above, limiting to {cropsector} stocks per sector and {cropindustry} per industry.\")\n",
    "#df = df.sort_values(by=['industry','score'], ascending=False).groupby('industry').head(cropindustry).sort_values(by=['sector','score'], ascending=False).groupby('sector').head(cropsector).sort_values(by=['eee','Δ1W%','score'], ascending=False)\n",
    "\n",
    "df = df.sort_values(by=['eee','ROEpct'], ascending=False)\n",
    "\n",
    "df.drop([ 'sortCur', 'vwdId', 'vwdIdSecondary', 'StmCur', 'StmPrice', 'ΔΔEPS1-3', 'ΔΔEPS3-5',\"ΔEPS3\", \"ΔEPS5\",\"ROE5Ypct\", 'ΔROE', 'ΔREV5', 'ΔREV3', 'ΔΔREV1-3', 'ΔΔREV3-5', 'ΔΔNPM1-5', \"ΔNPM5\",'QLTD2EQ','QCURRATIO'], axis=1, inplace=True)\n",
    "df = df.fillna(\"—\")\n",
    "df = df[df.sector.str.match('.*(Basic Materials|Healthcare).*', case=False)]\n",
    "\n",
    "print('Please read the readme.rtf to get the meaning of all the columns.')\n",
    "print(f'Screener result has {df.shape[0]} lines')\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374982e3-5db2-4d27-b447-b8412c907488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Writing raw stock list\n",
    "write2csv(info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac91ba9-11cf-4b0d-ba9d-cab57113e222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replacing favourite list based on filtered stock list\n",
    "write2fav(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe07523-4641-42f5-bbfe-161a8714e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying Current Portfolio\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from degiro_connector.trading.models.trading_pb2 import Credentials, ProductSearch\n",
    "import degiro_connector.core.helpers.pb_handler as pb_handler\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "from multiprocessing import  Pool\n",
    "from functools import partial\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import math\n",
    "import itertools\n",
    "from BourseDirect import BourseDirect\n",
    "from cachedApi import cachedApi\n",
    " \n",
    "\n",
    "#Trying to fetch portfolio from Degiro\n",
    "try: pf\n",
    "except NameError: pf = None\n",
    "\n",
    "if pf is None:\n",
    "    username = os.getenv(\"GT_DG_USERNAME\") or \"\"\n",
    "    password = os.getenv(\"GT_DG_PASSWORD\") or \"\"\n",
    "    if username == \"\" or password == \"\":\n",
    "        print(\"Won't download DEGIRO portfolio\")\n",
    "        pass\n",
    "    else:\n",
    "        credentials = Credentials(\n",
    "            int_account=None, # updated by get_client_details()\n",
    "            username=username,\n",
    "            password=password,\n",
    "        )\n",
    "        trading_api = cachedApi('/home/fab/GamestonkTerminal/.cachedb',credentials)\n",
    "        trading_api.connect()\n",
    "        trading_api.get_products_config(raw=True)\n",
    "        trading_api.get_client_details()\n",
    "        update = trading_api.get_portfolio()\n",
    "        update_dict = pb_handler.message_to_dict(message=update)\n",
    "        pf = pd.DataFrame(update_dict['portfolio']['values'])\n",
    "        trading_api.logout()\n",
    "\n",
    "        pf=pf.drop(pf.index[ (pf['positionType'] != 'PRODUCT') | (pf['value'] <= 0) ])\n",
    "        pf.set_index('id', inplace = True)\n",
    "        pf['plBase'] = pf.apply(lambda x: -x['plBase']['EUR'], axis=1)\n",
    "        pf['todayPlBase'] = pf.apply(lambda x: -x['todayPlBase']['EUR'], axis=1)\n",
    "        pf['P/L(€)'] = pf['todayPlBase'] - pf['plBase']\n",
    "        pf.rename(columns = {'todayPlBase':'Value(€)'}, inplace = True)  \n",
    "        pf.drop(columns=pf.columns.difference(['P/L(€)', 'Value(€)', 'action']), axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Trying to fetch portfolio from BourseDirect\n",
    "try: bd_info\n",
    "except NameError: bd_info = None\n",
    "\n",
    "if bd_info is None:\n",
    "    username = os.getenv(\"GT_BD_USERNAME\") or \"\"\n",
    "    password = os.getenv(\"GT_BD_PASSWORD\") or \"\"\n",
    "    if username == \"\" or password == \"\":\n",
    "        print(\"Won't download BourseDirect portfolio\")\n",
    "        pass\n",
    "    else:\n",
    "        bd = BourseDirect(Display=True, login=username, password=password, download_path=None)\n",
    "        bd_info = bd.show_portfolio()\n",
    "        bd.close_connection()\n",
    "\n",
    "\n",
    "# Merging raw stock list data with current portfolio on DEGIRO and portfolio on BourseDirect\n",
    "df = info_df.copy()\n",
    "df.reset_index(inplace=True)  \n",
    "if not bd_info is None:\n",
    "    df = pd.merge(bd_info,df, left_index=False, right_index=False, how='left', left_on='ticker', right_on='symbol',copy=True)\n",
    "df.dropna(subset=['Cur'], inplace=True)\n",
    "df=df.drop(df.index[ ~ (  (df['Cur'].str.contains('EUR'))   )])\n",
    "df.drop_duplicates(keep = 'first', subset = ['name_x'], inplace=True)\n",
    "df.set_index('id', inplace = True)\n",
    "df.drop(columns=df.columns.difference(['Valo','+/-Val.']), axis=1, inplace=True)\n",
    "df.rename(columns = {'Valo':'Value(€)', '+/-Val.':'P/L(€)'}, inplace=True)\n",
    "if not pf is None:\n",
    "    merged = pd.concat([pf, df])\n",
    "else:\n",
    "    merged = df\n",
    "merged['action']='Keep'\n",
    "\n",
    "df = info_df.copy()\n",
    "split=10**(max(1,math.floor(math.log(info_df.shape[0],10))-1))\n",
    "df['score'] = pd.qcut(df['score'].rank(method='first'),q=split, retbins=False, labels=False)\n",
    "df=pd.merge(merged,df, left_index=True, right_index=True)\n",
    "df.loc[df.index[ (df['%M200D'] <0) | ( df['%M200D'].isna() & (df['L%H'] < 40))], ['action']] = 'Sell'\n",
    "df.dropna(subset=['P/L(€)'], inplace=True)\n",
    "df.drop(columns=[ 'sortCur', 'vwdId', 'vwdIdSecondary', 'StmCur', 'StmPrice', 'ΔΔEPS1-3', 'ΔΔEPS3-5',\"ΔEPS3\", \"ΔEPS5\",\"ROE5Ypct\", \\\n",
    "          'ΔROE', 'ΔREV5', 'ΔREV3', 'ΔΔREV1-3', 'ΔΔREV3-5', 'ΔΔNPM1-5', \"ΔNPM5\",'QLTD2EQ','QCURRATIO' ], axis=1, inplace=True)\n",
    "df = df.sort_values(by=['Value(€)'], ascending=False)\n",
    "\n",
    "# Displaying the merged portfolio, with data from raw stock list\n",
    "print(\"Stock Portfolio:\")\n",
    "display(df.head(200))\n",
    "\n",
    "# collate stocks by sector, compute percentage per sector\n",
    "df = df.groupby(\n",
    "    ['sector'], as_index=False).agg(\n",
    "    {'Value(€)':sum, 'P/L(€)':sum,}\n",
    ").rename(columns = {'Value(€)':'%'})\n",
    "s = df['%'].sum() / 100\n",
    "df['%'] /= s\n",
    "df.set_index('sector', inplace = True)\n",
    "df.sort_values(by=['%'], ascending=False, inplace=True)\n",
    "\n",
    "# Displaying portfolio dispatch per sector\n",
    "print(\"Percentage per sector:\")\n",
    "display(df)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457b304c-9281-47b0-b6c6-2543e1ae5511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd25af9f-f728-4d31-9845-4e43ed5da4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
