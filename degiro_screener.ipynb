{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb576b4-48cc-4041-8af5-68fe32324428",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# IMPORTATIONS\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "from typing import List\n",
    "from degiro_connector.trading.api import API as TradingAPI\n",
    "from degiro_connector.trading.models.trading_pb2 import Credentials, ProductSearch, ProductsInfo, Update\n",
    "import shelve\n",
    "from degiro_connector.quotecast.api import API as QuotecastAPI\n",
    "from degiro_connector.quotecast.actions.action_get_chart import ChartHelper\n",
    "from degiro_connector.quotecast.models.quotecast_pb2 import Chart\n",
    "import degiro_connector.core.helpers.pb_handler as pb_handler\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "#from datetime import date\n",
    "from datetime import timedelta\n",
    "import traceback\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.interpolate import interp1d\n",
    "import re\n",
    "from multiprocessing import  Pool\n",
    "from functools import partial\n",
    "import yfinance as yf\n",
    "import threading, time, random\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from concurrent.futures import as_completed\n",
    "import math\n",
    "import itertools\n",
    "\n",
    "class cachedApi:\n",
    "    def __init__(self, file:str, credentials=Credentials):\n",
    "        self.__db = shelve.open(file)\n",
    "        self.__trading_api = TradingAPI(credentials=credentials)\n",
    "        self.__user_token = None\n",
    "        self.__quotecast_api = None\n",
    "        self.mutex = threading.Lock()\n",
    "        \n",
    "    def logout(self):\n",
    "        self.__trading_api.logout()\n",
    "    \n",
    "    def cache_get(self, k):\n",
    "        r = None\n",
    "        #self.mutex.acquire()\n",
    "        try:\n",
    "            r = self.__db[k]\n",
    "        except:\n",
    "            None\n",
    "        #self.mutex.release()\n",
    "        return r\n",
    "\n",
    "    def cache_set(self, k,v):\n",
    "        self.mutex.acquire()\n",
    "        self.__db[k] = v\n",
    "        self.mutex.release()\n",
    "    \n",
    "    def get_config(self):\n",
    "        return self.__trading_api.credentials\n",
    "\n",
    "    def get_config(self,**kwargs):\n",
    "        k = 'get_config' + str(kwargs)\n",
    "        r = self.cache_get(k)\n",
    "        if r is None:\n",
    "            r = self.__trading_api.get_config(**kwargs)\n",
    "            self.cache_set(k,r)\n",
    "        #print(r)\n",
    "        self.__user_token = r['clientId']\n",
    "        #print(f\"token:{self.__user_token}\")\n",
    "        return r\n",
    "\n",
    "    def get_client_details(self,**kwargs):\n",
    "        k = 'get_client_details' + str(kwargs)\n",
    "        r = self.cache_get(k)\n",
    "        if r is None:\n",
    "            r = self.__trading_api.get_client_details(**kwargs)\n",
    "            self.cache_set(k,r)\n",
    "        #print(r)\n",
    "        self.__trading_api.credentials.int_account = r[\"data\"][\"intAccount\"]\n",
    "        #print(f\"intAccount:{self.__trading_api.credentials.int_account}\")\n",
    "        return r\n",
    "    \n",
    "    def connect(self):\n",
    "        self.__trading_api.connect()\n",
    "        if not self.__user_token:\n",
    "            self.get_config()\n",
    "        if self.__user_token:\n",
    "            self.__quotecast_api = QuotecastAPI(user_token=self.__user_token)   \n",
    "        session_id = self.__trading_api.connection_storage.session_id\n",
    "        #print(\"You are now connected, with the session id :\", session_id)\n",
    "\n",
    "    def get_portfolio(self): \n",
    "        request_list = Update.RequestList()\n",
    "        request_list.values.extend([\n",
    "            Update.Request(option=Update.Option.PORTFOLIO, last_updated=0),\n",
    "        ])\n",
    "        return self.__trading_api.get_update(request_list=request_list)\n",
    "\n",
    "    def get_list_list(self):\n",
    "        return self.__trading_api.get_favourites_list(raw=True)\n",
    "\n",
    "    def create_favourite_list(self,**kwargs):\n",
    "        return self.__trading_api.create_favourite_list(**kwargs)\n",
    "    \n",
    "    def delete_favourite_list(self,**kwargs):\n",
    "        return self.__trading_api.delete_favourite_list(**kwargs)\n",
    "    \n",
    "    def put_favourite_list_product(self,**kwargs):\n",
    "        return self.__trading_api.put_favourite_list_product(**kwargs)\n",
    "    \n",
    "    def get_products_config(self,**kwargs):\n",
    "        k = 'get_products_config' + str(kwargs)\n",
    "        r = self.cache_get(k)\n",
    "        if r is None:\n",
    "            r = self.__trading_api.get_products_config(**kwargs)\n",
    "            self.cache_set(k,r)\n",
    "        self.indices = {}\n",
    "        for li in r['indices']:\n",
    "            self.indices[li['id']] = DictObj(li)\n",
    "        self.countries = {}\n",
    "        for li in r['countries']:\n",
    "            self.countries[li['id']] = DictObj(li)\n",
    "        self.exchanges = {}\n",
    "        for li in r['exchanges']:\n",
    "            self.exchanges[li['id']] = DictObj(li)      \n",
    "        self.stockCountries =  r['stockCountries']\n",
    "        return r\n",
    "     \n",
    "    def get_company_ratios(self,**kwargs):\n",
    "        k = 'get_company_ratios' + str(kwargs)\n",
    "        r = self.cache_get(k)\n",
    "        if r is None:\n",
    "            r = self.__trading_api.get_company_ratios(**kwargs)\n",
    "            self.cache_set(k,r)\n",
    "        try:\n",
    "            codes = {}\n",
    "                \n",
    "            if 'data' in r and 'currentRatios' in r['data'] and 'ratiosGroups' in r['data']['currentRatios']:\n",
    "                for an in r['data']['currentRatios']['ratiosGroups']:\n",
    "                    for i in an['items']:\n",
    "                        v = i.get('value') or np.NaN  # value\n",
    "                        t = i.get('type') or None # type of parameter\n",
    "                        k = i.get('id') or None # name of parameter\n",
    "                        m = i.get('name') or \"\" # meaning\n",
    "                        if t == 'N' and not pd.isna(v): v = float(v)\n",
    "                        #elif t == 'D': v = datetime.strptime(v, '%Y-%m-%dT%H:%M:%S') #pd.to_datetime(v)\n",
    "                        if not m.__contains__(' per '): v = v * 1#000000\n",
    "                        if k:\n",
    "                            codes[k] = { 'meaning':m, 'value':v }\n",
    "\n",
    "            if 'data' in r and 'forecastData' in r['data'] and 'ratios' in r['data']['forecastData']:\n",
    "                for i in r['data']['forecastData']['ratios']:\n",
    "                    #print(i)\n",
    "                    v = i.get('value') or np.NaN  # value\n",
    "                    t = i.get('type') or None # type of parameter\n",
    "                    k = i.get('id') or None # name of parameter\n",
    "                    m = i.get('name') or \"\" # meaning\n",
    "                    if t == 'N' and not pd.isna(v): v = float(v)\n",
    "                    #elif t == 'D': v = datetime.strptime(v, '%Y-%m-%dT%H:%M:%S') #pd.to_datetime(v)\n",
    "                    if not m.__contains__(' per '): v = v * 1#000000\n",
    "                    if k:\n",
    "                        codes[k] = { 'meaning':m, 'value':v }\n",
    "\n",
    "            if 'data' in r and 'consRecommendationTrend' in r['data'] and 'ratings' in r['data']['consRecommendationTrend']:\n",
    "                for i in r['data']['consRecommendationTrend']['ratings']:\n",
    "                    #print(i)\n",
    "                    v = i.get('value') or np.NaN  # value\n",
    "                    k = ('ratings_'+i.get('periodType')) or None # name of parameter\n",
    "                    if t == 'N' and not pd.isna(v): v = float(v)\n",
    "                    #elif t == 'D': v = datetime.strptime(v, '%Y-%m-%dT%H:%M:%S') #pd.to_datetime(v)\n",
    "                    if not m.__contains__(' per '): v = v * 1#000000\n",
    "                    if k:\n",
    "                        codes[k] = { 'meaning':'', 'value':v }\n",
    "                    \n",
    "            codes['priceCurrency'] = { 'meaning':'', 'value':r['data']['currentRatios']['priceCurrency'] }\n",
    "            if len(codes['priceCurrency']) <= 1:\n",
    "                codes['priceCurrency'] = { 'meaning':'', 'value':r['data']['currentRatios']['currency'] }\n",
    "        except:\n",
    "            None\n",
    "        return codes\n",
    "\n",
    "    def get_financial_statements(self,**kwargs):\n",
    "        k = 'get_financial_statements' + str(kwargs)\n",
    "        r = self.cache_get(k)\n",
    "        if r is None:\n",
    "            r = self.__trading_api.get_financial_statements(**kwargs)\n",
    "            self.cache_set(k,r)\n",
    "        codes_array = []\n",
    "        if r:\n",
    "            try:\n",
    "                for t in ('annual','interim'):\n",
    "                    if t in r['data']:\n",
    "                        for an in r['data'][t]:\n",
    "                                endDate = datetime.strptime(an.get('endDate'), '%Y-%m-%d')#T%H:%M:%S')\n",
    "                                fiscalYear = an.get('fiscalYear')\n",
    "                                periodNumber = an.get('periodNumber') or 'Y'\n",
    "                                codes = {}\n",
    "                                for st in an['statements']:\n",
    "                                    periodLength = st.get('periodLength')\n",
    "                                    periodType = st.get('periodType')\n",
    "                                    for i in st['items']:\n",
    "                                        v = i.get('value') or np.NaN \n",
    "                                        if not pd.isna(v): v = float(v)\n",
    "                                        if not i.get('meaning').__contains__(' per '): v = v * 1#000000\n",
    "                                        codes[i.get('code')] = { 'meaning':i.get('meaning'), 'value':v }\n",
    "                                codes_array += [ codes ]\n",
    "            except:\n",
    "                #print(k)\n",
    "                #traceback.print_exc()\n",
    "                #del self.cache_get(k)\n",
    "                None\n",
    "        return codes_array\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_estimates_summaries(self,**kwargs):\n",
    "        k = 'get_estimates_summaries_' + str(kwargs)\n",
    "        r = self.cache_get(k)\n",
    "            #print(\"get_estimates_summaries cache hit\", type(r))\n",
    "        if r is None:\n",
    "            r = self.__trading_api.get_estimates_summaries(**kwargs)\n",
    "            #print(\"get_estimates_summaries cache miss\", type(r))\n",
    "            self.cache_set(k,r)\n",
    "        return r\n",
    "    \n",
    "    def get_products_info(self,**kwargs):\n",
    "        k = 'get_products_info' + str(kwargs)\n",
    "        r = self.cache_get(k)\n",
    "            #print(\"get_products_info cache hit\", r)\n",
    "        if r is None:\n",
    "            r = self.__trading_api.get_products_info(**kwargs)\n",
    "            #print(\"get_products_info cache miss\", r)\n",
    "            self.cache_set(k,r)\n",
    "        return r\n",
    "\n",
    "    def get_chart(self,**kwargs):\n",
    "        k = 'get_chart' + str(kwargs)\n",
    "        r = self.cache_get(k)\n",
    "            #print(\"get_chart cache hit\", r)\n",
    "        if r is None:\n",
    "            r = self.__quotecast_api.get_chart(**kwargs)\n",
    "            #print(\"get_chart cache miss\", r)\n",
    "            self.cache_set(k,r)\n",
    "        return r\n",
    "   \n",
    "    def product_search(self,**kwargs):\n",
    "        k = 'product_search' + str(kwargs)\n",
    "        r = self.cache_get(k)\n",
    "        if r is None:\n",
    "            r = self.__trading_api.product_search(**kwargs)\n",
    "#        if hasattr(r, 'products'):\n",
    "            self.cache_set(k,r)\n",
    "#        else:\n",
    "#            r = None\n",
    "        return r\n",
    "\n",
    "    def get_longtermprice(self,vwdIdSecondary:str):\n",
    "        qrequest = Chart.Request()\n",
    "        qrequest.culture = \"fr-FR\"\n",
    "        qrequest.period = Chart.Interval.P1Y\n",
    "        qrequest.requestid = \"1\"\n",
    "        qrequest.resolution = Chart.Interval.P1D\n",
    "        qrequest.series.append(\"ohlc:\"+vwdIdSecondary)\n",
    "        qrequest.tz = \"Europe/Paris\"\n",
    "        k = 'get_chart' + str(qrequest)\n",
    "        chart = self.cache_get(k)\n",
    "        if chart is None:\n",
    "            chart = trading_api.get_chart(request=qrequest,raw=False)\n",
    "            self.cache_set(k,chart)\n",
    "        price = pd.DataFrame()\n",
    "        try:\n",
    "            c2=ChartHelper.format_chart(chart=chart, copy=False)\n",
    "            price = ChartHelper.serie_to_df(serie=chart.series[0])\n",
    "            price[\"timestamp\"] = pd.to_datetime(price[\"timestamp\"], unit=\"s\")\n",
    "        except:\n",
    "            #print(f\"Error chart {vwdIdSecondary}\")\n",
    "            None\n",
    "        #price.set_index(\"timestamp\", inplace=True)\n",
    "        return price\n",
    "\n",
    "\n",
    "    def get_company_profile(self,**kwargs):\n",
    "        k = 'get_company_profile' + str(kwargs)\n",
    "        r = self.cache_get(k)\n",
    "        if r is None:\n",
    "            #searching on Degiro\n",
    "            r = self.__trading_api.get_company_profile(product_isin=kwargs['product_isin'], raw=kwargs['raw'])\n",
    "            self.cache_set(k,r)\n",
    "        \n",
    "        codes = {}\n",
    "        if r is not None and 'data' in r:\n",
    "            r_data = r['data']\n",
    "            try:\n",
    "                codes['sector'] = r_data['sector']\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                codes['industry'] =  r_data['industry']\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                codes['country'] =  r_data['contacts']['COUNTRY']\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                codes['floatShares'] = float(r_data['shrFloating']) / 10**6\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                codes['businessSummary'] = r_data['businessSummary']\n",
    "            except:\n",
    "                None\n",
    "   \n",
    "            try:\n",
    "                if 'ratios' in r_data and 'ratiosGroups' in r_data['ratios']:\n",
    "                    for an in r_data['ratios']['ratiosGroups']:\n",
    "                        for i in an['items']:\n",
    "                            v = i.get('value') or np.NaN  # value\n",
    "                            t = i.get('type') or None # type of parameter\n",
    "                            k = i.get('id') or None # name of parameter\n",
    "                            m = i.get('name') or \"\" # meaning\n",
    "                            if t == 'N' and not pd.isna(v): v = float(v)\n",
    "                            #elif t == 'D': v = datetime.strptime(v, '%Y-%m-%dT%H:%M:%S') #pd.to_datetime(v)\n",
    "                            if not m.__contains__(' per '): v = v * 1#000000\n",
    "                            if k:\n",
    "                                codes[k] = { 'meaning':m, 'value':v }\n",
    "                if 'forecastData' in r_data and 'ratios' in r_data['forecastData']:\n",
    "                    for i in r_data['forecastData']['ratios']:\n",
    "                        #print(i)\n",
    "                        v = i.get('value') or np.NaN  # value\n",
    "                        t = i.get('type') or None # type of parameter\n",
    "                        k = i.get('id') or None # name of parameter\n",
    "                        m = i.get('name') or \"\" # meaning\n",
    "                        if t == 'N' and not pd.isna(v): v = float(v)\n",
    "                        #elif t == 'D': v = datetime.strptime(v, '%Y-%m-%dT%H:%M:%S') #pd.to_datetime(v)\n",
    "                        if not m.__contains__(' per '): v = v * 1#000000\n",
    "                        if k:\n",
    "                            codes[k] = { 'meaning':m, 'value':v }\n",
    "            except:\n",
    "                None\n",
    "        else: \n",
    "            # searching on Yahoo! finance\n",
    "            try:\n",
    "                r = self.cache_get('Y_'+k)\n",
    "            except:\n",
    "                sym = yf.Ticker(kwargs['product_isin'])\n",
    "                r = sym.info\n",
    "                try:\n",
    "                    r['marketCap'] /= 1000.0\n",
    "                except:\n",
    "                    pass\n",
    "                self.cache_set('Y_'+k, r)\n",
    "                print(f\"OK from Yahoo {kwargs['product_isin']}\")\n",
    "            codes = r\n",
    "        return codes\n",
    "\n",
    "\n",
    "def isna(num):\n",
    "    return num!= num    \n",
    "\n",
    "def get(d,k):\n",
    "    r = np.NaN # sys.float_info.epsilon #float(\"nan\")np.NaN\n",
    "    if d is not None and (type(d) is dict) and k in d:\n",
    "        r = d[k]\n",
    "        if (type(r) is dict) and ('value' in r):\n",
    "            r = r['value']\n",
    "    else:\n",
    "        r = np.NaN\n",
    "    return r\n",
    "\n",
    "def getmin(d,a): # get min of defined parameter in array a\n",
    "    r = 10**6\n",
    "    isset = False\n",
    "    for p in a:\n",
    "        v = get(d, p)\n",
    "        if v == v:\n",
    "            r = min(r, v)\n",
    "            isset = True\n",
    "    if isset:\n",
    "        return r\n",
    "    else:\n",
    "        return np.NaN\n",
    "            \n",
    "    \n",
    "def yget(d,k):\n",
    "    r = np.NaN # sys.float_info.epsilon #float(\"nan\")np.NaN\n",
    "    if d is not None and k in d:\n",
    "        r=d[k]\n",
    "        if (type(r) is dict) and ('value' in r):\n",
    "            r = r['value']\n",
    "    else:\n",
    "        r = np.NaN\n",
    "    try:\n",
    "        r = float(r)\n",
    "    except:\n",
    "        r = str(r)\n",
    "        if r == 'None' or r == '':\n",
    "            r = np.NaN\n",
    "    return r\n",
    "\n",
    "def write2fav(df):\n",
    "    if (df.shape[0] > 0):\n",
    "        username = os.getenv(\"GT_DG_USERNAME\") or \"\"\n",
    "        password = os.getenv(\"GT_DG_PASSWORD\") or \"\"\n",
    "\n",
    "        if username == \"\" or password == \"\":\n",
    "            exit(0)\n",
    "\n",
    "        credentials = Credentials(\n",
    "            int_account=None, # updated by get_client_details()\n",
    "            username=username,\n",
    "            password=password,\n",
    "        )\n",
    "\n",
    "\n",
    "        trading_api = cachedApi('/home/fab/GamestonkTerminal/.cachedb',credentials)\n",
    "        trading_api.connect()\n",
    "        trading_api.get_products_config(raw=True)\n",
    "        trading_api.get_client_details()\n",
    "        \n",
    "        now = datetime.now()\n",
    "        prefix='Screener-'\n",
    "        fl = trading_api.get_list_list()\n",
    "        #print(fl)\n",
    "        for l in fl['data']:\n",
    "            if 'name' in l and l['name'].startswith(prefix):\n",
    "                trading_api.delete_favourite_list(id=l['id'])\n",
    "                print(f'Deleting DEGIRO favourite list \\\"{l[\"name\"]}\\\"')\n",
    "        name=prefix+now.strftime(\"%Y-%m-%d-%H-%M\")\n",
    "        print(f'Creating DEGIRO favourite list \\\"{name}\\\"')\n",
    "        favorite_list_id = trading_api.create_favourite_list(name=name)\n",
    "        for p in df.index[:50].tolist():  \n",
    "            # list is limited to 50 entries\n",
    "            trading_api.put_favourite_list_product(id=favorite_list_id,product_id=p)\n",
    "            #print(f'Adding product id {p}')\n",
    "        trading_api.logout() \n",
    "\n",
    "def write2csv(df):\n",
    "    now = datetime.now() # current date and time\n",
    "    filename=\"degiro-export-\"+now.strftime(\"%Y-%m-%d-%H-%M\")+\".csv\"\n",
    "    filepath='.'\n",
    "    fullpath=os.path.join(filepath,filename)\n",
    "    print(f\"Writing csv file '{fullpath}' (encoding utf-8)\")\n",
    "    df.to_csv(fullpath, index=True, sep=str(';'), decimal=str(','),encoding='utf-8', )\n",
    "\n",
    "        \n",
    "def parallelize_dataframe(df, func, n_cores=os.cpu_count()):\n",
    "    df_split = np.array_split(df, n_cores)\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df\n",
    "\n",
    "def assess_map(product, eee):\n",
    "    p = DictObj(dict(product))\n",
    "    row = {}\n",
    "    #if p.isin != 'PTGNV0AM0001': return row\n",
    "    #print(p)\n",
    "    try:\n",
    "        company_profile = trading_api.get_company_profile(product_isin=p.isin, raw=True)\n",
    "        row['symbol'] = p.symbol\n",
    "        row['isin'] = p.isin\n",
    "        row['id'] = p.id\n",
    "        row['vwdId'] = f'{p.vwdIdentifierType}:{p.vwdId}' if hasattr(p, 'vwdId') and hasattr(p, 'vwdIdentifierType') else ''\n",
    "        row['vwdIdSecondary'] = f'{p.vwdIdentifierTypeSecondary}:{p.vwdIdSecondary}' if hasattr(p, 'vwdIdSecondary') and hasattr(p, 'vwdIdentifierTypeSecondary') else ''\n",
    "        \n",
    "        row['name'] = p.name.upper()\n",
    "        row['sector'] =   yget(company_profile, 'sector')  \n",
    "        row['industry'] = yget(company_profile, 'industry')\n",
    "        '''\n",
    "        desc = yget(company_profile, 'businessSummary')\n",
    "        if desc is not None and type(desc) == str:\n",
    "            desc = desc.upper()\n",
    "            if re.match(r'.*((POTASH|NITROGEN|PHOSPHATE|CROP NUTRIENT|CROP INPUT|FERTILIZER|FEEDING).*?){3}', desc):\n",
    "                row['industry'] = '!!' + row['industry']\n",
    "        '''\n",
    "        if isinstance(row['industry'], str): row['industry'] = row['industry'].replace(' (NEC)', '')\n",
    "        row['country'] = yget(company_profile, 'country') \n",
    "        row['eee'] = 1 if row['country'] in eee else 0\n",
    "        \n",
    "        row['volume'] = get(company_profile,\"VOL10DAVG\") or yget(company_profile, 'volume')\n",
    "        #row['volume'] = row['volume'] / 1000 if not pd.isna(row['volume'])\n",
    "        row['marketCap'] = get(company_profile,\"MKTCAP\") or yget(company_profile, 'marketCap')  \n",
    "        if not pd.isna(row['marketCap']):\n",
    "            row['marketCap'] /= 1000\n",
    "        row['closePrice'] = p.closePrice if hasattr(p, 'closePrice') else 0 # price shown on screen, depends on the stock exchange\n",
    "        row['Cur'] = p.currency if hasattr(p, 'currency') else '' # currency shown on screen\n",
    "        if row['Cur'] == 'EUR':\n",
    "            row['sortCur'] = 3 # sortCur is a temp column used to determine which exchange to keep when a stock is listed on different place. Higher value means more change to be selected\n",
    "        elif row['Cur'] == 'USD':\n",
    "            row['sortCur'] = 1\n",
    "        else:\n",
    "            row['sortCur'] = 0\n",
    "\n",
    "        codes = trading_api.get_company_ratios(product_isin=p.isin, raw=True)\n",
    "        #display(codes)\n",
    "        row['StmPrice'] = get(codes,\"NPRICE\") # price used to compute statements, ratio, etc\n",
    "        row['StmCur'] = get(codes,\"priceCurrency\") # currency used to compute market capitalization, statements, ratio, etc\n",
    "        row['Δ1Y%'] = get(codes,\"PR52WKPCT\") # price diff 1 year\n",
    "        row['Δ13W%'] = get(codes,\"PR13WKPCT\") # price diff 3 months\n",
    "        row['Δ1W%'] = get(codes,\"PR5DAYPRC\") # price diff 1 week\n",
    "        row['Δ1D%'] =get(codes,\"PR1DAYPRC\")\n",
    "\n",
    "        if row['vwdId']:\n",
    "            df = trading_api.get_longtermprice(row['vwdId'])\n",
    "            df = df[-200:]\n",
    "            mean200D = np.NaN\n",
    "            if df.shape[0] == 200:\n",
    "                mean200D = df['close'].mean()\n",
    "                row['%M200D'] = (row['closePrice'] - mean200D) / mean200D\n",
    "            elif df.shape[0] == 0 and row['vwdIdSecondary']:\n",
    "                df = trading_api.get_longtermprice(row['vwdIdSecondary'])\n",
    "                df = df[-200:]\n",
    "                mean200D = np.NaN\n",
    "                if df.shape[0] == 200:\n",
    "                    mean200D = df['close'].mean()\n",
    "                    row['%M200D'] = (row['closePrice'] - mean200D) / mean200D\n",
    "        if not '%M200D'in row:\n",
    "            row['%M200D'] = np.NaN\n",
    "            #print(f\"Cannot get 200-day chart data for {p.name}\")\n",
    "        \n",
    "        h = get(codes,\"NHIG\")\n",
    "        l = get(codes,\"NLOW\")\n",
    "        row['L%H'] = int(100*(row['StmPrice'] - l)/(h-l)) if not pd.isna(h) and not pd.isna(l) and not pd.isna(row['StmPrice']) and h>l else np.NaN\n",
    "\n",
    "        row['Yield'] =  get(codes,'YLD5YAVG') # dividend yield\n",
    "        row['Payout'] =  get(codes,'TTMPAYRAT') # dividend yield\n",
    "        row['β'] = get(codes,\"BETA\") # correlation \n",
    "        row['Reco'] = get(codes,'ratings_CURR') # current recommendation\n",
    "        row['ΔFOCF5'] = get(codes,'FOCF_AYr5CAGR') # increase of free operational cash flow, 5Y CAGR\n",
    "        row['P/FCF'] = get(codes,'TTMPRFCFPS') # Price to Free Cash Flow per Share - trailing 12 months\n",
    "\n",
    "        a = get(codes,'TTMFCF') # Free Cash Flow - trailing 12 month\n",
    "        b = get(codes,'TTMNIAC') # Net Income available to common - trailing 12 months\n",
    "        row['FCF/NI'] = a/b if not pd.isna(a) and not pd.isna(b) and b > 0 else np.NaN\n",
    "\n",
    "        \n",
    "        row['ΔREV'] = get(codes,\"REVCHNGYR\")  # Revenue Change % - most recent quarter 1 year ago\n",
    "        row['ΔREV3'] = get(codes,\"REVGRPCT\")  # \"Growth rate% -  Revenue, 3 year\";\n",
    "        row['ΔREV5'] = get(codes,\"REVTRENDGR\")  # \"Revenue growth rate, 5 year\"; REVPS5YGR \"Revenue/share (5 yr growth)\"; -- should be > 0\n",
    "        if pd.isna(row['ΔREV5']):\n",
    "            row['ΔREV5'] = yget(company_profile, 'revenueGrowth')\n",
    "        row['ΔΔREV1-3'] = row['ΔREV'] - row['ΔREV3']\n",
    "        row['ΔΔREV3-5'] = row['ΔREV3'] - row['ΔREV5'] \n",
    "        \n",
    "        row['ΔNPM'] = get(codes,\"TTMNPMGN\") # Net Profit Margin % - trailing 12 month\"\n",
    "        row['ΔNPM5'] = get(codes,\"NPMTRENDGR\") # \"Net Profit Margin growth rate, 5 year\"; -- should be > 0\n",
    "        row['ΔΔNPM1-5'] = row['ΔNPM'] - row['ΔNPM5'] \n",
    "        \n",
    "        row['ΔEPS'] = get(codes,'TTMEPSCHG')   # latest \"Growth rate% - EPS, TTM\";\n",
    "        if pd.isna(row['ΔEPS']):\n",
    "            row['ΔEPS'] = yget(company_profile, 'earningsGrowth')\n",
    "        row['ΔEPS3'] = get(codes,\"EPSGRPCT\")   # \"EPS Growth rate % - , 3 year CAGR\";\n",
    "        row['ΔEPS5'] = get(codes,\"EPSTRENDGR\") # \"EPS growth rate %, 5 year CAGR\";\n",
    "\n",
    "        row['ΔΔEPS1-3'] = row['ΔEPS'] - row['ΔEPS3']\n",
    "        row['ΔΔEPS3-5'] = row['ΔEPS3'] - row['ΔEPS5'] \n",
    "        row['ROEpct'] = get(codes,'TTMROEPCT')           # Return on average equity - trailing 12 month -- should be >20%\n",
    "        if pd.isna(row['ROEpct']):\n",
    "            row['ROEpct'] = yget(company_profile, 'returnOnEquity')\n",
    "        row['ROE5Ypct'] = get(codes,'AROE5YAVG')         # Return on average equity avg 5Y -- should be >20%\n",
    "        \n",
    "        row['ΔROE'] = row['ROEpct'] - row['ROE5Ypct'] \n",
    "        \n",
    "        row['P2TB'] = get(codes,'APR2TANBK')             # price to tangible book\n",
    "        #row['dP2TB'] = get(codes,'BVTRENDGR')           # growth of price to tangible book, 5Y CAGR\n",
    "        row['P2B'] = get(codes,'APRICE2BK')              # price to  book\n",
    "        if pd.isna(row['P2B']):\n",
    "            row['P2B'] = yget(company_profile, 'priceToBook')\n",
    "        #row['dP2B'] = get(codes,'TanBV_AYr5CAGR')       # growth of P25B, 5Y\n",
    "        row['PCF'] =  get(codes,'TTMPRCFPS')             # \"Price to Cash Flow per share, near 1 idealy\n",
    "\n",
    "        row['PE'] = get(codes,'PEINCLXOR')               #  P/E including extraordinary items - TTM - should be <50%\n",
    "        if pd.isna(row['PE']):\n",
    "            row['PE'] = yget(company_profile, 'trailingPE')\n",
    "        row['fPE'] = get(codes,'ProjPE')          # forward PE\n",
    "        if pd.isna(row['fPE']):\n",
    "            row['fPE'] = yget(company_profile, 'forwardPE')\n",
    "\n",
    "        row['PEG'] = row['PE'] / row['ΔEPS3'] if row['ΔEPS3'] and row['ΔEPS3']>0 else np.NaN # PEG ratio, should be <1\n",
    "        if pd.isna(row['PEG']):\n",
    "            row['PEG'] = yget(company_profile, 'pegRatio')\n",
    "        row['fPEG'] = row['fPE'] / row['ΔEPS3']  if row['ΔEPS3'] and row['ΔEPS3']>0 else np.NaN    # forward PEG ratio, should be <1\n",
    "\n",
    "        row['PS'] = get(codes,'TTMPR2REV')               #  Price to sales - trailing 12 month  -- should be between 2 to 4\n",
    "        if pd.isna(row['PS']):\n",
    "            row['PS'] = yget(company_profile, 'priceToSalesTrailing12Months')\n",
    "        row['fPS'] = get(codes,'Price2ProjSales') # forward PS -- should be 2 to 4/\n",
    "            \n",
    "        row['%DEBT'] =  get(codes,'QTOTD2EQ') #\"Total debt/total equity, percent, should be <100%\n",
    "        row['QLTD2EQ'] =  get(codes,'QLTD2EQ') #\"Total debt/total equity, percent, should be <100%\n",
    "        row['QCURRATIO'] =  get(codes,'QCURRATIO') #\"Total debt/total equity, percent, should be <100%\n",
    "        if pd.isna(row['%DEBT']):\n",
    "            row['%DEBT'] = yget(company_profile, 'debtToEquity')\n",
    "        row['%DEBT'] = round(row['%DEBT']) if not pd.isna(row['%DEBT']) else np.NaN\n",
    "        row['BV'] =  get(codes,'QBVPS') # QTANBVPS\n",
    "        if pd.isna(row['BV']):\n",
    "            row['BV'] =  get(codes,'ABVPS') # ATANBVPS\n",
    "        if pd.isna(row['BV']):\n",
    "            row['BV'] =  get(codes,'QTANBVPS')  \n",
    "        if pd.isna(row['BV']):\n",
    "            row['BV'] =  get(codes,'ATANBVPS')  \n",
    "        if pd.isna(row['BV']):\n",
    "            row['BV'] =  yget(company_profile, 'bookValue')\n",
    "        row['BV'] =  (1 * (row['BV'] - row['StmPrice']) / row['StmPrice']) if not pd.isna(row['BV']) and not pd.isna(row['StmPrice']) and row['BV'] > 0 and row['StmPrice'] > 0 else np.NaN \n",
    "        \n",
    "        # book value tangible / share price, last quarter >100% is fair\n",
    "\n",
    "        # ratio : intrinsic value from free cash flow per share / price per share - should be > 100%\n",
    "        # gain of free cash flow CAGR5Y is not available on DEGIRO, so I consider \"free operational\" cash flow\n",
    "        dFOCF =  get(codes,'FOCF_AYr5CAGR') # gain of  free operational cash flow, CAGR 5 year.\n",
    "        FCFS = get(codes,'TTMFCFSHR')   # free Cash Flow per share  - trailing 12 month\n",
    "        row['IV'] = FCFS*((1-((1+dFOCF/100)*0.85)**10)/(1-((1+dFOCF/100)*0.85))+10*(((1+dFOCF/100)*0.85)**10)) if not pd.isna(dFOCF) and not pd.isna(FCFS) else np.NaN\n",
    "        row['IV'] = (1*(FCFS-row['StmPrice'])/row['StmPrice']) if not pd.isna(row['StmPrice']) and row['StmPrice']>0 and not pd.isna(row['IV']) else np.NaN\n",
    "        \n",
    "        try:\n",
    "            # 1/ EPS\n",
    "            eps = get(codes,\"TTMEPSINCX\")   # \"EPS including extraordinary items - trailing 12 month\";\n",
    "            if not pd.isna(eps):\n",
    "                # 2/ growth rate min des 2 là, ou ΔEPS5?\n",
    "                gr = getmin(codes,[\"REVTRENDGR\", \"TanBV_AYr5CAGR\"]) #, \"EPSTRENDGR\", \"EPSGRPCT\"\n",
    "                # 3/ projPE ou le double du précédent, min\n",
    "                if not pd.isna(row['fPE']):\n",
    "                    ppe = min (row['fPE'], 2* gr)\n",
    "                else:\n",
    "                    ppe = 2* gr\n",
    "                fsv = eps*((1+gr/100)**5)*ppe/2                        \n",
    "                row['FV'] = (fsv-row['StmPrice'])/row['StmPrice'] # 0=> stock price will double in 5 years          \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        #dFOCF \tFCFS\n",
    "        #BVS = get(codes,'ABVPS') #Book value (Total Equity) per share - most recent fiscal year\n",
    "        #FCF = p.StmPrice / get(codes,'TTMPRFCFPS') # Price to Free Cash Flow per Share - trailing 12 months\" \n",
    "        #dREV3 = get(codes,\"REVGRPCT\") #\"Growth rate% -  Revenue, 3 year\";\n",
    "        #dBVS5 = get(codes,\"BVTRENDGR\") #\"Book value per share growth rate, 5 year\";\n",
    "        #dTBE5 = get(codes,\"TanBV_AYr5CAGR\") #\"Tangible Book Value, Total Equity, 5 Year CAGR\";\n",
    "        #dCSP5 = get(codes,\"CSPTRENDGR\") # \"Capital Spending growth rate, 5 year\";      \n",
    "        #row['EV/EBITD'] = EV/EBITD if EV and EBITD and EBITD>0 else 0\n",
    "\n",
    "    except:\n",
    "        print(f\"Error profile {p.symbol}\")\n",
    "        traceback.print_exc()\n",
    "    return row    \n",
    "\n",
    "def myassess(country, stock_list, info_df):\n",
    "    eee = {}\n",
    "    try:\n",
    "        eee = {k:1 for k in pd.read_csv(\"eee.csv\", header=None).T.values[0]}\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        if hasattr(stock_list, 'products'):\n",
    "            with ThreadPoolExecutor(max_workers = os.cpu_count()) as executor:\n",
    "                results = executor.map(assess_map, stock_list.products, itertools.repeat(eee))\n",
    "            for row in results:\n",
    "                info_df = info_df.append(row,ignore_index=True)\n",
    "        else:\n",
    "            print(\"Stock market as no product\", country)\n",
    "        #info_df = info_df.astype({'FV':'Int64', 'IV':'Int64', 'BV' :'Int64','%DEBT' :'Int64','L%H':'Int64','eee':'Int64'})\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        pass\n",
    "    return info_df\n",
    "\n",
    "class DictObj:\n",
    "    def __init__(self, in_dict:dict):\n",
    "        assert isinstance(in_dict, dict)\n",
    "        for key, val in in_dict.items():\n",
    "            if isinstance(val, (type(list), type(tuple))):\n",
    "               setattr(self, key, [DictObj(x) if isinstance(x, dict) else x for x in val])\n",
    "            else:\n",
    "               setattr(self, key, DictObj(val) if isinstance(val, dict) else val)\n",
    "\n",
    "#############            \n",
    "            \n",
    "logging.basicConfig(level=logging.FATAL) #\n",
    "\n",
    "username = os.getenv(\"GT_DG_USERNAME\") or \"\"\n",
    "password = os.getenv(\"GT_DG_PASSWORD\") or \"\"\n",
    "\n",
    "if username == \"\" or password == \"\":\n",
    "    exit(0)\n",
    "    \n",
    "credentials = Credentials(\n",
    "    int_account=None, # updated by get_client_details()\n",
    "    username=username,\n",
    "    password=password,\n",
    ")\n",
    "\n",
    "\n",
    "trading_api = cachedApi('/home/fab/GamestonkTerminal/.cachedb',credentials)\n",
    "trading_api.connect()\n",
    "\n",
    "try:\n",
    "    # get all product list, countries, marketplaces\n",
    "    products_config_dict = trading_api.get_products_config(raw=True)\n",
    "    # get IntAccount\n",
    "    trading_api.get_client_details()\n",
    "\n",
    "    # this is the main dataframe that will be filled up\n",
    "    info_df = pd.DataFrame()\n",
    "    \n",
    "    # stocked are browsed from counties(, and not marketplaces). This is the most reliable to get all stocks\n",
    "    for li_dict in trading_api.stockCountries:\n",
    "        li = DictObj(li_dict)\n",
    "        stock_country_id = li.id\n",
    "        country = trading_api.countries[li.country].name\n",
    "        #if country != 'FR': continue\n",
    "        # it's assumed that a country has less than 10x1000 stocks, so we browse up to 10 pages and stop once we got a partial page\n",
    "        for page in range(0,10):\n",
    "            request_stock = ProductSearch.RequestStocks(stock_country_id=stock_country_id,limit=1000,offset=page*1000,require_total=True)\n",
    "            stock_list = trading_api.product_search(request=request_stock, raw=False)\n",
    "            if hasattr(stock_list, 'products'):\n",
    "                size = len(stock_list.products)\n",
    "                print(f\"country:{country} list:All ({size} stocks for page {page+1})\")\n",
    "                # dowload data for all stocks in the list. It's multi-thread even though the cache system is mono-thread...\n",
    "                if stock_list: info_df = myassess(country, stock_list, info_df) \n",
    "                #for p in stock_list.products:\n",
    "                #    assess_map(p, {})\n",
    "                if size != 1000: break\n",
    "            else:\n",
    "                break\n",
    "    print(f\"Number of stock entries in all exchanges: {info_df.shape[0]}\")\n",
    "    info_df.set_index('id', inplace = True)\n",
    "       \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(repr(e))\n",
    "    traceback.print_exc()\n",
    "\n",
    "try:\n",
    "    trading_api.logout()\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(repr(e))\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829a1b97-b444-4c2e-a7cb-3432ae80bd09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def var2rank(X,Y,x):\n",
    "    r = 1 # default return if x is nan\n",
    "    try:\n",
    "        if x == x:\n",
    "            y_interp = interp1d(x=X, y=Y,fill_value=(Y[0], Y[-1]), bounds_error=False)\n",
    "            r = float(y_interp(x))\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "        None\n",
    "    return r\n",
    "\n",
    "def var2quant(x,Q,name): \n",
    "    Y = Q.index.to_numpy()\n",
    "    Y = (Y-Y[0])/(Y[-1]-Y[0])+1\n",
    "    Y = np.asarray(Y)\n",
    "    X=list(Q[name].to_dict().values())\n",
    "    r = var2rank(X,Y,x[name])\n",
    "    return r\n",
    "\n",
    "def compute_rank(info_df, Q, k):\n",
    "    info_df['score'] = 1\n",
    "    for key, value in k.items():\n",
    "        info_df['score'] *= info_df.apply(lambda x: var2quant(x,Q,key), axis = 1) ** value\n",
    "    return info_df\n",
    "\n",
    "\n",
    "######         \n",
    "\n",
    "# compute quantile of all numeric parameters\n",
    "Q = info_df.quantile(q=[0.1,0.25,0.5,0.75,0.9])\n",
    "\n",
    "# per sector, correlation between 1YTTM gain and all other parameters. \n",
    "# Conglomerates are removed since result is the opposite from all other sector\n",
    "# then we merge all sector by computing the mean of correlation factor for each parameter\n",
    "#gainCorrelation=info_df.drop(info_df.index[ (info_df['Δ1Y%'] < Q['Δ1Y%'][0.75]) ])\n",
    "gainCorrelation=info_df.groupby('sector').corrwith(info_df['Δ1Y%'],method ='spearman').mean(axis=0)\n",
    "# Only some parameters are considered to compute the score\n",
    "gainCorrelation = gainCorrelation[ [\\\n",
    "                                    \"QLTD2EQ\", \"QCURRATIO\", \"Payout\", \"Yield\", \"β\", \\\n",
    "                                    \"Reco\", \"ΔFOCF5\", \"P/FCF\", \"FCF/NI\", \"ΔREV5\", \\\n",
    "                                    'ΔREV', 'ΔREV3', 'ΔΔREV1-3', 'ΔΔREV3-5', 'ΔΔNPM1-5', \\\n",
    "                                    \"ΔNPM5\", \"ΔNPM\", \"ΔEPS\", \"ΔEPS3\", \"ΔEPS5\", \\\n",
    "                                    'ΔΔEPS1-3', 'ΔΔEPS3-5', \"ROEpct\", \"ROE5Ypct\", 'ΔROE', \\\n",
    "                                    \"P2TB\", \"P2B\", \"PCF\", \"PE\", \"fPE\", \\\n",
    "                                    \"PEG\", \"fPEG\", \"PS\", \"fPS\", \"%DEBT\" ] ]\n",
    "# we normalize the power factors, we add the 1YTTM back in the table\n",
    "gainMax=gainCorrelation.abs().mean()\n",
    "gainCorrelation=gainCorrelation/gainMax\n",
    "gainCorrelation=dict(gainCorrelation.sort_values(ascending = False))\n",
    "gainCorrelation['Δ1Y%']=1\n",
    "\n",
    "#display(gainCorrelation)\n",
    "\n",
    "# compute the score for all stocks, using all CPU cores\n",
    "if info_df.shape[0] > os.cpu_count():\n",
    "    info_df = parallelize_dataframe(info_df,partial(compute_rank, Q=Q, k=gainCorrelation))\n",
    "else:\n",
    "    compute_rank(info_df, Q, gainCorrelation)\n",
    "\n",
    "info_df=info_df.sort_values(by='score', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425b8b0-eb9a-44dc-9bd3-acdce4c2cffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 40)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "\n",
    "#display(info_df[:1])\n",
    "split=10**(max(1,math.floor(math.log(info_df.shape[0],10))-1))\n",
    "keeptop=math.floor(split*0.95)\n",
    "cropsector=10#max(5,math.floor(split/50))\n",
    "cropindustry=2#max(1,math.floor(cropsector/5))\n",
    "df = info_df.copy()\n",
    "\n",
    "# we remove duplicates when a stock is listed on several exchanges.\n",
    "df = df.sort_values(by=['name', 'sortCur', 'vwdId'], ascending = False).drop_duplicates(keep = 'first', subset = 'name')\n",
    "df = df.sort_values(by=['isin', 'sortCur', 'vwdId'], ascending = False).drop_duplicates(keep = 'first', subset = 'isin')\n",
    "print(f\"Number of stock entries after removing duplicates: {info_df.shape[0]}\")\n",
    "\n",
    "df['score'] = pd.qcut(df['score'].rank(method='first'),q=split, retbins=False, labels=False)\n",
    "df=df.drop(df.index[ (   (df['%M200D'] <0) | ((df['%M200D'].isna()) & (df['L%H'] < 45)) | (df['Δ1Y%'] < Q['Δ1Y%'][0.75])  | (df['score'] < keeptop) )])\n",
    "df=df.drop(df.index[ (  (df['IV'] < Q['IV'][0.5])   )])\n",
    "df=df.drop(df.index[ (  (df['ROE5Ypct'] < Q['ROE5Ypct'][0.5])   )])\n",
    "df=df.drop(df.index[ (  (df['Reco'] > Q['Reco'][0.75])   )])\n",
    "df=df.drop(df.index[ (  (df['%DEBT'] > Q['%DEBT'][0.9])   )])\n",
    "#df=df.drop(df.index[ ( (df['PE'] >Q['PE'][0.9]) | (df['%DEBT'] >Q['%DEBT'][0.9]) | (df['P2B'] >Q['P2B'][0.9]) | (df['Reco'] > Q['Reco'][0.5])  | (df['PEG'] > Q['PEG'][0.9])  | (df['IV'] < Q['IV'][0.5]) | (df['%M200D'] <0) | ((df['%M200D'].isna()) & (df['L%H'] < 45)) | (df['Δ1Y%'] < Q['Δ1Y%'][0.75])  )]) # | (df['PE'] >15) | (df['%DEBT'] >100) | (df['Δ1Y%'] < 8) |(df['P2TB'] >3) |(df['ΔREV5'] <5) |(df['ΔFOCF5'] <0) |(df['FV'] <-.50)  |(df['FCF/NI'] <0)\n",
    " # | (df['PE'] >15) | (df['%DEBT'] >100) | (df['Δ1Y%'] < 8) |(df['P2TB'] >3) |(df['ΔREV5'] <5) |(df['ΔFOCF5'] <0) |(df['FV'] <-.50)  |(df['FCF/NI'] <0)\n",
    "#df=df.drop(df.index[ (  | (df['sector'] == \"Financial\") | (df['sector'] == \"Transportation\") )]) #| (df['Reco'] > 2.4) | (df['Δ1Y%'] < 20) | (df['FCF/NI'] <0) |(df['P2B'] >15) |(df['ΔREV'] <0) | (df['%DEBT'] >120)  | (df['industry'].str.contains(\"harma\")) | (df['sector'].str.contains(\"inanc\")) |(df['FV'] <-.35)      | (df['PE'] >15) | (df['%DEBT'] >100) | (df['Δ1Y%'] < 8) |(df['P2TB'] >3) |(df['ΔREV5'] <5) |(df['ΔFOCF5'] <0) |(df['FV'] <-.50)  |(df['FCF/NI'] <0)\n",
    "\n",
    "#print(f\"Quantiles:{split}, keeping top {keeptop}th and above, limiting to {cropsector} stocks per sector and {cropindustry} per industry.\")\n",
    "#df = df.sort_values(by=['industry','score'], ascending=False).groupby('industry').head(cropindustry).sort_values(by=['sector','score'], ascending=False).groupby('sector').head(cropsector).sort_values(by=['eee','Δ1W%','score'], ascending=False)\n",
    "\n",
    "df = df.sort_values(by=['eee','ROEpct'], ascending=False)\n",
    "\n",
    "df.drop([ 'sortCur', 'vwdId', 'vwdIdSecondary', 'StmCur', 'StmPrice', 'ΔΔEPS1-3', 'ΔΔEPS3-5',\"ΔEPS3\", \"ΔEPS5\",\"ROE5Ypct\", 'ΔROE', 'ΔREV5', 'ΔREV3', 'ΔΔREV1-3', 'ΔΔREV3-5', 'ΔΔNPM1-5', \"ΔNPM5\",'QLTD2EQ','QCURRATIO'], axis=1, inplace=True)\n",
    "df = df.fillna(\"—\")\n",
    "df = df[df.sector.str.match('.*(Utilities|Healthcare|Basic Materials|Consumer/Non-Cyclical|Services).*')]\n",
    "\n",
    "print('Please read the readme.rtf to get the meaning of all the columns.')\n",
    "print(f'Screener result has {df.shape[0]} lines')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374982e3-5db2-4d27-b447-b8412c907488",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Writing raw stock list\n",
    "write2csv(info_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac91ba9-11cf-4b0d-ba9d-cab57113e222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replacing favourite list based on filtered stock list\n",
    "write2fav(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe07523-4641-42f5-bbfe-161a8714e085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging current portfolio on DEGIRO with raw stock list data\n",
    "\n",
    "username = os.getenv(\"GT_DG_USERNAME\") or \"\"\n",
    "password = os.getenv(\"GT_DG_PASSWORD\") or \"\"\n",
    "\n",
    "if username == \"\" or password == \"\":\n",
    "    exit(0)\n",
    "\n",
    "credentials = Credentials(\n",
    "    int_account=None, # updated by get_client_details()\n",
    "    username=username,\n",
    "    password=password,\n",
    ")\n",
    "\n",
    "\n",
    "trading_api = cachedApi('/home/fab/GamestonkTerminal/.cachedb',credentials)\n",
    "        \n",
    "trading_api.connect()\n",
    "trading_api.get_products_config(raw=True)\n",
    "trading_api.get_client_details()\n",
    "update = trading_api.get_portfolio()\n",
    "update_dict = pb_handler.message_to_dict(message=update)\n",
    "pf = pd.DataFrame(update_dict['portfolio']['values'])\n",
    "trading_api.logout()\n",
    "\n",
    "pf=pf.drop(pf.index[ (pf['positionType'] != 'PRODUCT') | (pf['value'] <= 0) ])\n",
    "pf.set_index('id', inplace = True)\n",
    "pf['plBase'] = pf.apply(lambda x: -x['plBase']['EUR'], axis=1)\n",
    "pf['todayPlBase'] = pf.apply(lambda x: -x['todayPlBase']['EUR'], axis=1)\n",
    "pf['P/L(€)'] = pf['todayPlBase'] - pf['plBase']\n",
    "pf.rename(columns = {'todayPlBase':'Value(€)'}, inplace = True)\n",
    "pf['action']='Keep'\n",
    "pf.drop(columns=pf.columns.difference(['P/L(€)', 'Value(€)', 'action']), axis=1, inplace=True)\n",
    "\n",
    "df = info_df.copy()\n",
    "split=10**(max(1,math.floor(math.log(info_df.shape[0],10))-1))\n",
    "df['score'] = pd.qcut(df['score'].rank(method='first'),q=split, retbins=False, labels=False)\n",
    "df=pd.merge(pf,df, left_index=True, right_index=True)\n",
    "df.loc[df.index[ (df['%M200D'] <0) | ( df['%M200D'].isna() & (df['L%H'] < 40))], ['action']] = 'Sell'\n",
    "df.dropna(subset=['P/L(€)'], inplace=True)\n",
    "df.drop(columns=[ 'sortCur', 'vwdId', 'vwdIdSecondary', 'StmCur', 'StmPrice', 'ΔΔEPS1-3', 'ΔΔEPS3-5',\"ΔEPS3\", \"ΔEPS5\",\"ROE5Ypct\", \\\n",
    "          'ΔROE', 'ΔREV5', 'ΔREV3', 'ΔΔREV1-3', 'ΔΔREV3-5', 'ΔΔNPM1-5', \"ΔNPM5\",'QLTD2EQ','QCURRATIO' ], axis=1, inplace=True)\n",
    "\n",
    "df = df.fillna(\"—\")\n",
    "print(\"Stock Portfolio:\")\n",
    "display(df.head(20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
